{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "766e482c",
   "metadata": {},
   "source": [
    "# Organizing DF for COVIDxCT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a95fda47",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.utils import resample\n",
    "\n",
    "train_df = pd.read_csv('/media/riccelli/Disco 1/datasets_covid/covidxct/train_COVIDx_CT-3A.txt', sep=\" \", header=None)\n",
    "train_df.columns=['filename', 'label', 'xmin','ymin','xmax','ymax']\n",
    "train_df=train_df.drop(['xmin', 'ymin','xmax', 'ymax'], axis=1 )\n",
    "#train_df = pd.read_csv('/media/riccelli/Disco 1/datasets_covid/covidxct/train_COVIDx_CT-3A_segmented.txt', sep=\" \", header=None)\n",
    "#train_df.columns=['filename', 'label']\n",
    "\n",
    "# 读取test.txt\n",
    "val_df = pd.read_csv('/media/riccelli/Disco 1/datasets_covid/covidxct/val_COVIDx_CT-3A.txt', sep=\" \", header=None)\n",
    "val_df.columns=['filename', 'label', 'xmin','ymin','xmax','ymax']\n",
    "val_df=val_df.drop(['xmin', 'ymin','xmax', 'ymax'], axis=1 )\n",
    "\n",
    "#test_df = pd.read_csv('/media/riccelli/Disco 1/datasets_covid/covidxct/test_COVIDx_CT-3A_segmented2.txt', sep=\" \", header=None)\n",
    "test_df = pd.read_csv('/media/riccelli/Disco 1/datasets_covid/covidxct/test_COVIDx_CT-3A.txt', sep=\" \", header=None)\n",
    "test_df.columns=['filename', 'label', 'xmin','ymin','xmax','ymax']\n",
    "#test_df.columns=['filename', 'label']\n",
    "test_df=test_df.drop(['xmin', 'ymin','xmax', 'ymax'], axis=1 )\n",
    "\n",
    "#train_df = train_df.drop(train_df[train_df['filename'].str.contains(\"COVIDCTMD\")].index)\n",
    "\n",
    "# covidctmd_val = val_df[val_df['filename'].str.contains(\"COVIDCTMD\")]\n",
    "# covidctmd_val = val_df[val_df['label']==0]\n",
    "# train_df = pd.concat([train_df, covidctmd_val])\n",
    "# val_df = val_df.drop(val_df[val_df['filename'].str.contains(\"COVIDCTMD\")].index)\n",
    "val_df = val_df.drop(val_df[val_df['label']==0].index)\n",
    "\n",
    "# covidctmd_test = test_df[test_df['filename'].str.contains(\"COVIDCTMD\")]\n",
    "# covidctmd_test = test_df[test_df['label']==0]\n",
    "# train_df = pd.concat([train_df, covidctmd_test])\n",
    "# test_df = test_df.drop(test_df[test_df['filename'].str.contains(\"COVIDCTMD\")].index)\n",
    "test_df = test_df.drop(test_df[test_df['label']==0].index)\n",
    "\n",
    "image_path = '/media/riccelli/Disco 1/datasets_covid/covidxct/3A_images/'  #directory path\n",
    "image_path2 = '/media/riccelli/Disco 1/datasets_covid/covidxct/3A_images_segmented/'  #directory path\n",
    "image_path3 = '/media/riccelli/Disco 1/datasets_covid/covidxct/3A_test_images_segmented2/'  #directory path\n",
    "# train_df['filename'] = image_path2+train_df['filename']\n",
    "# val_df['filename'] = image_path+val_df['filename']\n",
    "# test_df['filename'] = image_path3 + test_df['filename']\n",
    "train_df['filename'] = image_path+train_df['filename']\n",
    "val_df['filename'] = image_path+val_df['filename']\n",
    "test_df['filename'] = image_path + test_df['filename']\n",
    "\n",
    "\n",
    "# undersample\n",
    "#N  = train_df[train_df['label']==0]\n",
    "P = train_df[train_df['label']==1]\n",
    "C = train_df[train_df['label']==2]\n",
    "#N_download = resample(N, replace = True, n_samples = 25496,random_state=0)\n",
    "#P_download = resample(P, replace = True, n_samples = 5000,random_state=0)\n",
    "#C_download = resample(C, replace = True, n_samples = 5000,random_state=0)\n",
    "#P_download = resample(P, replace = True, n_samples = 2000,random_state=0)\n",
    "#C_download = resample(C, replace = True, n_samples = 1000,random_state=0)\n",
    "#train_df = pd.concat([P_download, C_download])\n",
    "\n",
    "# N_v  = val_df[val_df['label']==0]\n",
    "# P_v = val_df[val_df['label']==1]\n",
    "# C_v = val_df[val_df['label']==2]\n",
    "# N_v_download = resample(N_v, replace = True, n_samples = 6244,random_state=0)\n",
    "# #C_v_download = resample(C_v, replace = True, n_samples = 8008,random_state=0)\n",
    "# P_v_download = resample(P_v, replace = True, n_samples = 6244,random_state=0)\n",
    "# val_df = pd.concat([N_v_download, C_v, P_v_download])\n",
    "\n",
    "train_df.loc[train_df[\"label\"] == 1, \"label\"] = 0\n",
    "train_df.loc[train_df[\"label\"] == 2, \"label\"] = 1\n",
    "\n",
    "val_df.loc[val_df[\"label\"] == 1, \"label\"] = 0\n",
    "val_df.loc[val_df[\"label\"] == 2, \"label\"] = 1\n",
    "\n",
    "test_df.loc[test_df[\"label\"] == 1, \"label\"] = 0\n",
    "test_df.loc[test_df[\"label\"] == 2, \"label\"] = 1\n",
    "\n",
    "labels={0:'Pneumonia',1:'COVID-19'}\n",
    "class_names=['Pneumonia','COVID-19']\n",
    "\n",
    "train_df['label_n']=[labels[b] for b in train_df['label']]\n",
    "val_df['label_n']=[labels[b] for b in val_df['label']]\n",
    "test_df['label_n']=[labels[b] for b in test_df['label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "533b2a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Negative and positive values of train: \\n{train_df['label_n'].value_counts()}\")\n",
    "print(f\"Negative and positive values of validation: \\n{val_df['label_n'].value_counts()}\")\n",
    "print(f\"Negative and positive values of test: \\n{test_df['label_n'].value_counts()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbb57e9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df=train_df.reset_index()\n",
    "val_df=val_df.reset_index()\n",
    "test_df=test_df.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbdc1c43",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8025a094",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b73ae8e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "from get_lungs_vh_paper import get_lungs\n",
    "\n",
    "\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.Resize((224,224)),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomRotation([-15,15]),\n",
    "        transforms.GaussianBlur(3),\n",
    "        #transforms.RandomAdjustSharpness(0),\n",
    "        #transforms.RandomEqualize(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Resize((224,224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}\n",
    "\n",
    "class CovidDataset(Dataset):\n",
    "    def __init__(self, dataset_df, transform=None):\n",
    "        self.dataset_df = dataset_df\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.dataset_df.shape[0]\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        image_name = self.dataset_df['filename'][idx]\n",
    "        img = Image.open(image_name).convert('RGB')\n",
    "        label = self.dataset_df['label'][idx]\n",
    "        \n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "        return img, label\n",
    "    \n",
    "train_dataset = CovidDataset(train_df, data_transforms['train'])\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=20)\n",
    "\n",
    "val_dataset = CovidDataset(val_df, data_transforms['val'])\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=32, shuffle=False, num_workers=20)\n",
    "\n",
    "test_dataset = CovidDataset(test_df, data_transforms['val'])\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "506ade87",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "plt.rcParams['figure.figsize'] = [30, 20]\n",
    "\n",
    "def imshow_img(inp, title=None):\n",
    "    \"\"\"Imshow for Tensor.\"\"\"\n",
    "    inp = inp.numpy().transpose((1, 2, 0))\n",
    "    mean = np.array([0.485, 0.456, 0.406])\n",
    "    std = np.array([0.229, 0.224, 0.225])\n",
    "    inp = std * inp + mean\n",
    "    inp = np.clip(inp, 0, 1)\n",
    "    plt.imshow(inp)\n",
    "    if title is not None:\n",
    "        plt.title(title)\n",
    "    plt.pause(0.001)  # pause a bit so that plots are updated\n",
    "    \n",
    "# Get a batch of training data\n",
    "images, labels = next(iter(train_dataloader))\n",
    "\n",
    "# Make a grid from batch\n",
    "out = torchvision.utils.make_grid(images)\n",
    "print(labels)\n",
    "\n",
    "imshow_img(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2d4debf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from scipy import ndimage\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pydicom as dicom\n",
    "import os\n",
    "\n",
    "normal_path = '/media/riccelli/Disco 1/datasets_covid/spgc_after_segmentation/Normal'\n",
    "covid_path = '/media/riccelli/Disco 1/datasets_covid/spgc_after_segmentation/Covid'\n",
    "cp_path = '/media/riccelli/Disco 1/datasets_covid/spgc_after_segmentation/Pneumonia'\n",
    "\n",
    "normal_patient_paths = [\n",
    "    os.path.join(os.getcwd(), normal_path, x)\n",
    "    for x in os.listdir(normal_path)\n",
    "]\n",
    "\n",
    "covid_patient_paths = [\n",
    "    os.path.join(os.getcwd(), covid_path, x)\n",
    "    for x in os.listdir(covid_path)\n",
    "]\n",
    "\n",
    "cp_patient_paths = [\n",
    "    os.path.join(os.getcwd(), cp_path, x)\n",
    "    for x in os.listdir(cp_path)\n",
    "]\n",
    "\n",
    "patient_paths = np.concatenate((np.asarray(covid_patient_paths), np.asarray(cp_patient_paths), np.asarray(normal_patient_paths)))\n",
    "\n",
    "covidctmd_dataset = patient_paths\n",
    "\n",
    "print(\"Patients with healthy lung tissue: \" + str(len(normal_patient_paths)))\n",
    "\n",
    "print(\"Patients with covid symptoms in lung tissue: \" + str(len(covid_patient_paths)))\n",
    "print(\"Patients with common pneumonia symptoms in lung tissue: \" + str(len(cp_patient_paths)))\n",
    "\n",
    "\n",
    "#class_names = ['Healthy', 'Covid', 'Others']\n",
    "class_names = ['Pneumonia', 'Covid']\n",
    "idx_to_class = {i:j for i, j in enumerate(class_names)}\n",
    "class_to_idx = {value:key for key,value in idx_to_class.items()}\n",
    "\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "import torch\n",
    "import random\n",
    "\n",
    "class CustomExternalMDDataset(Dataset):\n",
    "    def __init__(self, paths, transform=None, target_transform=None):\n",
    "        self.paths = paths\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        path = self.paths[idx]\n",
    "        img = Image.open(path).convert('RGB')\n",
    "        img = transforms.functional.adjust_gamma(img, .8)\n",
    "        \n",
    "        label = path.split('/')[-2]\n",
    "        \n",
    "        if label == 'Normal':\n",
    "            label = 'Pneumonia'\n",
    "            \n",
    "        label = class_to_idx[label]\n",
    "        \n",
    "        \n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "        if self.target_transform:\n",
    "            label = self.target_transform(label)\n",
    "        return img, label\n",
    "    \n",
    "covidctmd_dataset = CustomExternalMDDataset(covidctmd_dataset, data_transforms['val'])\n",
    "covidctmd_dataloader = DataLoader(covidctmd_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d764f287",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import models\n",
    "from torchvision.models import ResNet50_Weights, SqueezeNet1_0_Weights\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "def set_parameter_requires_grad(model, feature_extracting):\n",
    "    if feature_extracting:\n",
    "        for param in model.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "def create_model(model_name, in_channels, num_classes, feature_extract, use_pretrained=True):\n",
    "    # Initialize these variables which will be set in this if statement. Each of these\n",
    "    #   variables is model specific.\n",
    "    model_ft = None\n",
    "    input_size = 0\n",
    "\n",
    "    if model_name == \"resnet\":\n",
    "        \"\"\" Resnet50\n",
    "        \"\"\"\n",
    "        #model_ft = models.resnet50(pretrained=use_pretrained)\n",
    "        model_ft = models.resnet50(weights=ResNet50_Weights.DEFAULT)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        num_ftrs = model_ft.fc.in_features\n",
    "        model_ft.fc = nn.Linear(num_ftrs, num_classes)\n",
    "        input_size = 224\n",
    "\n",
    "    elif model_name == \"vgg\":\n",
    "        \"\"\" VGG16_bn\n",
    "        \"\"\"\n",
    "        model_ft = models.vgg16_bn(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        num_ftrs = model_ft.classifier[6].in_features\n",
    "        model_ft.classifier[6] = nn.Linear(num_ftrs,num_classes)\n",
    "        input_size = 224\n",
    "\n",
    "    elif model_name == \"squeezenet\":\n",
    "        \"\"\" Squeezenet\n",
    "        \"\"\"\n",
    "        #model_ft = models.squeezenet1_0(weights=SqueezeNet1_0_Weights.DEFAULT)\n",
    "        model_ft = models.squeezenet1_0(weights='DEFAULT')\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        model_ft.classifier[1] = nn.Conv2d(512, num_classes, kernel_size=(1,1), stride=(1,1))\n",
    "        model_ft.num_classes = num_classes\n",
    "        input_size = 224\n",
    "        \n",
    "    elif model_name == \"mobilenet\":\n",
    "        \"\"\" MobileNet\n",
    "        \"\"\"\n",
    "        model_ft = models.mobilenet_v3_small(weights='DEFAULT')\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        num_ftrs = model_ft.classifier[3].in_features\n",
    "        model_ft.classifier[3] = nn.Linear(num_ftrs, num_classes)\n",
    "        model_ft.num_classes = num_classes\n",
    "        input_size = 224\n",
    "\n",
    "    elif model_name == \"densenet\":\n",
    "        \"\"\" Densenet\n",
    "        \"\"\"\n",
    "        model_ft = models.densenet201(weights='DEFAULT')\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        num_ftrs = model_ft.classifier.in_features\n",
    "        model_ft.classifier = nn.Linear(num_ftrs, num_classes)\n",
    "        input_size = 224\n",
    "\n",
    "    else:\n",
    "        print(\"Invalid model name, exiting...\")\n",
    "        exit()\n",
    "\n",
    "    return model_ft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0854932",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytorch_lightning as pl\n",
    "import torch.optim as optim\n",
    "from sklearn.metrics import classification_report\n",
    "import torchmetrics\n",
    "import torch\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, classification_report\n",
    "from sklearn.metrics import classification_report, accuracy_score, f1_score, precision_score, recall_score, confusion_matrix, ConfusionMatrixDisplay, mean_squared_error, mean_absolute_error\n",
    "\n",
    "\n",
    "class ClassificationModel(pl.LightningModule):\n",
    "    def __init__(self, model_name, model_hparams, optimizer_name, optimizer_hparams):\n",
    "        \"\"\"\n",
    "        Inputs:\n",
    "            model_name - Name of the model/CNN to run. Used for creating the model (see function below)\n",
    "            model_hparams - Hyperparameters for the model, as dictionary.\n",
    "            optimizer_name - Name of the optimizer to use. Currently supported: Adam, SGD\n",
    "            optimizer_hparams - Hyperparameters for the optimizer, as dictionary. This includes learning rate, weight decay, etc.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        # Exports the hyperparameters to a YAML file, and create \"self.hparams\" namespace\n",
    "        self.save_hyperparameters()\n",
    "        # Create model\n",
    "        self.model = create_model(model_name, model_hparams[\"in_channels\"], \n",
    "                                  model_hparams[\"num_classes\"], False, use_pretrained=True)\n",
    "        # Create loss module\n",
    "        self.loss_module = nn.CrossEntropyLoss()\n",
    "        \n",
    "    def forward(self, imgs):\n",
    "        # Forward function that is run when visualizing the graph\n",
    "        return self.model(imgs)\n",
    "    \n",
    "    def shared_step(self, batch, stage):\n",
    "        imgs, labels = batch\n",
    "        preds = self.model(imgs)\n",
    "        loss = self.loss_module(preds, labels)\n",
    "                \n",
    "        return {\n",
    "            \"loss\": loss,\n",
    "            \"labels\": labels,\n",
    "            \"preds\": preds\n",
    "        }\n",
    "    \n",
    "    def shared_epoch_end(self, outputs, stage):\n",
    "        labels = torch.cat([x[\"labels\"] for x in outputs]).cpu()\n",
    "        preds = torch.cat([x[\"preds\"] for x in outputs]).cpu().argmax(dim=-1)\n",
    "        \n",
    "        acc = (preds == labels).float().mean()\n",
    "        \n",
    "        if stage == 'test':\n",
    "        \n",
    "            #print(classification_report(labels, preds, target_names=['Normal', 'Pneumonia', 'Covid']))\n",
    "            print(classification_report(labels, preds, target_names=['Pneumonia', 'Covid']))\n",
    "\n",
    "            cm = confusion_matrix(labels, preds)\n",
    "            disp = ConfusionMatrixDisplay(confusion_matrix=cm,\n",
    "                                  #display_labels=['Normal', 'Pneumonia', 'Covid'])\n",
    "                                  display_labels=['Pneumonia', 'Covid'])\n",
    "            disp.plot(cmap='Blues')\n",
    "\n",
    "            plt.show()\n",
    "            \n",
    "            print(accuracy_score(labels, preds))\n",
    "            print(f1_score(labels, preds))\n",
    "            print(precision_score(labels, preds))\n",
    "            print(recall_score(labels, preds))\n",
    "            print(recall_score(labels, preds, pos_label=0))\n",
    "        \n",
    "        \n",
    "        metrics = {\n",
    "             f\"{stage}_acc\": acc,\n",
    "#             f\"{stage}_acc_pneumonia\": self.acc[1],\n",
    "#             f\"{stage}_acc_covid\": self.acc[2],\n",
    "#             f\"{stage}_f1_normal\": self.f1[0],\n",
    "#             f\"{stage}_f1_pneumonia\": self.f1[1],\n",
    "#             f\"{stage}_f1_covid\": self.f1[2],\n",
    "#             #f\"{stage}_precision\": accuracy,\n",
    "#             #f\"{stage}_recall\": f1_score,\n",
    "            \n",
    "         }\n",
    "        \n",
    "        self.log_dict(metrics, prog_bar=True)\n",
    "        \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        return self.shared_step(batch, \"train\")            \n",
    "\n",
    "    def training_epoch_end(self, outputs):\n",
    "        return self.shared_epoch_end(outputs, \"train\")\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        return self.shared_step(batch, \"val\")\n",
    "\n",
    "    def validation_epoch_end(self, outputs):\n",
    "        return self.shared_epoch_end(outputs, \"val\")\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        return self.shared_step(batch, \"test\")  \n",
    "\n",
    "    def test_epoch_end(self, outputs):\n",
    "        return self.shared_epoch_end(outputs, \"test\")\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        if self.hparams.optimizer_name == \"Adam\":\n",
    "            return optim.AdamW(self.parameters(), **self.hparams.optimizer_hparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc4bce2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "# from pytorch_lightning.loggers import WandbLogger\n",
    "from pprint import pprint\n",
    "from random import randint\n",
    "\n",
    "random_num = randint(0,10000)\n",
    "\n",
    "model_name = 'densenet'\n",
    "#model_hparams={\"in_channels\": 1, \"num_classes\": 3, \"act_fn_name\": \"relu\"}\n",
    "model_hparams={\"in_channels\": 1, \"num_classes\": 2, \"act_fn_name\": \"relu\"}\n",
    "optimizer_name=\"Adam\"\n",
    "optimizer_hparams={\"lr\": 1e-4, \"weight_decay\": 1e-4}\n",
    "\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "                        dirpath='/media/riccelli/Disco 1/datasets_covid/covidxct/weights',    \n",
    "                        filename=f'covidxct-{model_name}-{random_num}',\n",
    "                        monitor='val_acc',\n",
    "                        mode=\"max\",\n",
    "                        )\n",
    "\n",
    "#valid per_image_iou\n",
    "early_stop_callback = EarlyStopping(\n",
    "                        monitor=\"val_acc\", \n",
    "                        patience=5, \n",
    "                        verbose=False, \n",
    "                        mode=\"max\"\n",
    "                        )\n",
    "\n",
    "model = ClassificationModel(model_name, model_hparams, optimizer_name, \n",
    "                            optimizer_hparams) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "491c33fc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "trainer = pl.Trainer(\n",
    "    accelerator=\"gpu\", \n",
    "    devices=1, \n",
    "    precision=16,\n",
    "    max_epochs=10,\n",
    "    callbacks = [checkpoint_callback, early_stop_callback],\n",
    "    accumulate_grad_batches=2,\n",
    "    )\n",
    "\n",
    "trainer.fit(\n",
    "    model, \n",
    "    train_dataloaders=train_dataloader, \n",
    "    #val_dataloaders=val_dataloader,\n",
    "    #val_dataloaders=covidctmd_dataloader,\n",
    "    val_dataloaders=val_dataloader,\n",
    "    )\n",
    "        \n",
    "    #Load best\n",
    "ckpt_path = f'/media/riccelli/Disco 1/datasets_covid/covidxct/weights/covidxct-{model_name}-{random_num}.ckpt'\n",
    "loaded_model = ClassificationModel.load_from_checkpoint(ckpt_path)    \n",
    "    \n",
    "#     # run test dataset\n",
    "test_metrics = trainer.test(model, dataloaders=covidctmd_dataloader, verbose=False)\n",
    "pprint(test_metrics)\n",
    "\n",
    "test_metrics = trainer.test(loaded_model, dataloaders=covidctmd_dataloader, verbose=False)\n",
    "pprint(test_metrics)\n",
    "\n",
    "os.remove(ckpt_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c300eff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#     # run test dataset\n",
    "test_metrics = trainer.test(model, dataloaders=covidctmd_dataloader, verbose=False)\n",
    "pprint(test_metrics)\n",
    "\n",
    "test_metrics = trainer.test(loaded_model, dataloaders=covidctmd_dataloader, verbose=False)\n",
    "pprint(test_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feb9f013",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_metrics = trainer.test(loaded_model, dataloaders=test_dataloader, verbose=False)\n",
    "pprint(test_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a666d09",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
