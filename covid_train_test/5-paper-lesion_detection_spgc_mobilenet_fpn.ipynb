{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94344b28",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from scipy import ndimage\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pydicom as dicom\n",
    "import os\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "import random\n",
    "\n",
    "def process_covidctmd(exam_path):\n",
    "    image_paths = sorted(os.listdir(exam_path))\n",
    "    \n",
    "    exam_dict = {}\n",
    "    for image_path in image_paths:\n",
    "        path = os.path.join(exam_path, str(image_path).replace(\"b'\",\"\").replace(\"'\", \"\"))\n",
    "        \n",
    "        ds = dicom.dcmread(path)\n",
    "    \n",
    "        volume = ds.pixel_array\n",
    "        \n",
    "        slope = 1\n",
    "        intercept = -1024\n",
    "        volume = (volume*slope+intercept) \n",
    "\n",
    "        img_min = -1250\n",
    "        img_max = 250\n",
    "        volume[volume<img_min] = img_min \n",
    "        volume[volume>img_max] = img_max\n",
    "        volume = (volume - img_min) / (img_max - img_min)*255.0 \n",
    "        volume = cv2.cvtColor(volume.astype(np.uint8), cv2.COLOR_GRAY2RGB)\n",
    "    \n",
    "        exam_dict[ds.SliceLocation] = volume # might sort dict if necessary\n",
    "        \n",
    "    return resize_volume_covidctmd(np.array(list(exam_dict.values())))\n",
    "\n",
    "def resize_volume_covidctmd(img):\n",
    "    \"\"\"Resize across z-axis\"\"\"\n",
    "    # Set the desired depth\n",
    "    desired_depth = img.shape[0]\n",
    "    desired_width = 512\n",
    "    desired_height = 512\n",
    "    # Get current depth\n",
    "    current_depth = img.shape[0]\n",
    "    # Compute depth factor\n",
    "    depth = current_depth / desired_depth\n",
    "    depth_factor = 1 / depth\n",
    "    # Resize across z-axis\n",
    "        \n",
    "    img = np.flip(img, 2)\n",
    "    return np.array(img)\n",
    "\n",
    "normal_path = '/media/riccelli/Disco 1/datasets_covid/spgc_dataset/Normal'\n",
    "covid_path = '/media/riccelli/Disco 1/datasets_covid/spgc_dataset/Covid'\n",
    "cp_path = '/media/riccelli/Disco 1/datasets_covid/spgc_dataset/Cap Cases'\n",
    "\n",
    "\n",
    "normal_patient_paths = [\n",
    "    os.path.join(os.getcwd(), normal_path, x)\n",
    "    for x in os.listdir(normal_path)\n",
    "]\n",
    "\n",
    "covid_patient_paths = [\n",
    "    os.path.join(os.getcwd(), covid_path, x)\n",
    "    for x in os.listdir(covid_path)\n",
    "]\n",
    "\n",
    "cp_patient_paths = [\n",
    "    os.path.join(os.getcwd(), cp_path, x)\n",
    "    for x in os.listdir(cp_path)\n",
    "]\n",
    "\n",
    "abnormal_patient_paths = np.concatenate((np.asarray(covid_patient_paths), np.asarray(cp_patient_paths)))\n",
    "\n",
    "patient_paths = np.concatenate((np.asarray(normal_patient_paths), np.asarray(abnormal_patient_paths)))\n",
    "\n",
    "covidctmd_dataset = patient_paths\n",
    "\n",
    "print(\"Patients with healthy lung tissue: \" + str(len(normal_patient_paths)))\n",
    "print(\"Patients with covid symptoms in lung tissue: \" + str(len(covid_patient_paths)))\n",
    "print(\"Patients with common pneumonia symptoms in lung tissue: \" + str(len(cp_patient_paths)))\n",
    "\n",
    "class_names = ['Normal', 'Covid']\n",
    "idx_to_class = {i:j for i, j in enumerate(class_names)}\n",
    "class_to_idx = {value:key for key,value in idx_to_class.items()}\n",
    "\n",
    "class CustomExternalMDDataset(Dataset):\n",
    "    def __init__(self, paths, transform=None, target_transform=None):\n",
    "        self.paths = paths\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        path = self.paths[idx]\n",
    "        exam = process_covidctmd(path)\n",
    "        label = path.split('/')[-2]\n",
    "        \n",
    "        if label == 'Cap Cases':\n",
    "            label = 'Covid'\n",
    "        \n",
    "        label = class_to_idx[label]\n",
    "        \n",
    "        if self.transform:\n",
    "            exam = exam\n",
    "        if self.target_transform:\n",
    "            label = self.target_transform(label)\n",
    "        return exam, label, path\n",
    "    \n",
    "covidctmd_dataset = CustomExternalMDDataset(covidctmd_dataset)\n",
    "covidctmd_dataloader = DataLoader(covidctmd_dataset, batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2f78dbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def imshow_img(inp, title=None):\n",
    "    \"\"\"Imshow for Tensor.\"\"\"\n",
    "    inp = inp.numpy().transpose((1, 2, 0))\n",
    "    plt.imshow(inp)\n",
    "    if title is not None:\n",
    "        plt.title(title)\n",
    "    plt.pause(0.001)  # pause a bit so that plots are updated\n",
    "    \n",
    "def imshow_mask(inp, title=None):\n",
    "    \"\"\"Imshow for Tensor.\"\"\"\n",
    "    inp = inp.numpy().transpose((1, 2, 0))\n",
    "    plt.imshow(inp)\n",
    "    if title is not None:\n",
    "        plt.title(title)\n",
    "    plt.pause(0.001)  # pause a bit so that plots are updated\n",
    "\n",
    "\n",
    "# Get a batch of training data\n",
    "inputs, labels, path = next(iter(covidctmd_dataloader))\n",
    "inputs = inputs.squeeze().permute(0,3,1,2)\n",
    "# Make a grid from batch\n",
    "out = torchvision.utils.make_grid(inputs)\n",
    "print(labels)\n",
    "\n",
    "imshow_img(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dff290b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "from get_lungs_vh_paper import get_lungs\n",
    "from get_lesions_vh_paper import get_lesions\n",
    "import re\n",
    "\n",
    "plt.rcParams['figure.figsize'] = [20, 10]\n",
    "\n",
    "j = 1\n",
    "\n",
    "y_true = []\n",
    "y_pred = []\n",
    "perc_true = []\n",
    "perc_pred = []\n",
    "severity_true = []\n",
    "severity_pred = []\n",
    "\n",
    "for exam, label, path in iter(covidctmd_dataloader):\n",
    "    exam = exam.numpy().squeeze()#.transpose(0,3,1,2)\n",
    "    \n",
    "    # para cada batch segmenta o pulmÃ£o\n",
    "    segmented_lung_inputs, predicted_lung_inputs = get_lungs(exam, \n",
    "                                                             resize=False, \n",
    "                                                             return_masks=True,\n",
    "                                                             weight=2)\n",
    "    \n",
    "    segmented_lesion_inputs, predicted_lesion_inputs = get_lesions(segmented_lung_inputs, \n",
    "                                                             resize=False, \n",
    "                                                             return_masks=True,\n",
    "                                                             weight='Mobilenet FPN',\n",
    "                                                             thresh=0.7) # >0.7\n",
    "    biggest_lesion_image_idx = None\n",
    "    biggest_lesion_area = 0.\n",
    "    exam_percentage = []\n",
    "    images_with_lesion = 0\n",
    "    exam_lesion_area = 0\n",
    "    for i in range(exam.shape[0]):\n",
    "        \n",
    "        lung_area = np.count_nonzero(predicted_lung_inputs[i,:,:,:])\n",
    "        \n",
    "        if lung_area > 0:\n",
    "            lesion_area = np.count_nonzero(predicted_lesion_inputs[i,:,:,:])\n",
    "            if lesion_area > 0:\n",
    "                images_with_lesion = images_with_lesion + 1\n",
    "                image_percentage = lesion_area/lung_area\n",
    "                exam_percentage.append(image_percentage)\n",
    "                exam_lesion_area = exam_lesion_area + lesion_area\n",
    "            \n",
    "                if lesion_area > biggest_lesion_area:\n",
    "                    biggest_lesion_image_idx = i\n",
    "                    biggest_lesion_area = lesion_area\n",
    "    \n",
    "    if len(exam_percentage) > 0:\n",
    "        cal_exam_percentage = np.mean(exam_percentage)\n",
    "    else:\n",
    "        cal_exam_percentage = 0\n",
    "        \n",
    "    if images_with_lesion > 3 and exam_lesion_area > 1500:\n",
    "        pred_label = 1\n",
    "    else:\n",
    "        pred_label = 0\n",
    "\n",
    "        \n",
    "    print(f'Exam path {path[0].split(\"/\")[-2:]}')\n",
    "    print(f'Exam {j} label: {label.item()}, Predicted label: {pred_label}')\n",
    "    print(f'Images with lesion {images_with_lesion} and Biggest Lesion area {biggest_lesion_area} and Exam lesion area {exam_lesion_area}')\n",
    "    \n",
    "    if biggest_lesion_image_idx != None:\n",
    "        plt.subplot(141)\n",
    "        plt.axis('off')\n",
    "        plt.imshow(exam[biggest_lesion_image_idx,:,:,:])\n",
    "        plt.subplot(142)\n",
    "        plt.axis('off')\n",
    "        plt.imshow(segmented_lung_inputs[biggest_lesion_image_idx,:,:,:])\n",
    "        plt.subplot(143)\n",
    "        plt.axis('off')\n",
    "        plt.imshow(predicted_lesion_inputs[biggest_lesion_image_idx,:,:,:])\n",
    "        \n",
    "        plt.subplot(144)\n",
    "        img = (predicted_lesion_inputs[biggest_lesion_image_idx,:,:,:][:,:,0]).astype(np.uint8)\n",
    "        contours, hierarchy = cv2.findContours(img, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        painted_img = cv2.drawContours(exam[biggest_lesion_image_idx,:,:,:].copy(), contours, -1, (255,0,0), 2)\n",
    "        img2 = (predicted_lung_inputs[biggest_lesion_image_idx,:,:,:][:,:,0]).astype(np.uint8)\n",
    "        contours, hierarchy = cv2.findContours(img2, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        painted_img = cv2.drawContours(painted_img, contours, -1, (0,255,0), 2)\n",
    "        plt.axis('off')\n",
    "        plt.imshow(painted_img)\n",
    "        plt.show()\n",
    "        \n",
    "    j = j+1\n",
    "    \n",
    "    \n",
    "    \n",
    "    perc_pred.append(cal_exam_percentage)    \n",
    "    y_true.append(label.item())\n",
    "    y_pred.append(pred_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3265c9f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, accuracy_score, f1_score, precision_score, recall_score, confusion_matrix, ConfusionMatrixDisplay, mean_squared_error, mean_absolute_error\n",
    "\n",
    "acc = accuracy_score(y_true, y_pred)\n",
    "f1 = f1_score(y_true, y_pred)\n",
    "prec = precision_score(y_true, y_pred)\n",
    "rec = recall_score(y_true, y_pred)\n",
    "spec = recall_score(y_true, y_pred, pos_label=0)\n",
    "print(f\"MobilenetV2 FPN & {round(acc*100,2)} & {round(f1*100,2)} & {round(prec*100,2)} & {round(rec*100,2)} & {round(spec*100,2)} \\\\\\\\\")  \n",
    "\n",
    "confusion_matrix = confusion_matrix(y_true, y_pred)\n",
    "cm_display = ConfusionMatrixDisplay(confusion_matrix = confusion_matrix, display_labels = ['Normal', 'Covid'])\n",
    "cm_display.plot(cmap=\"Blues\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d043577",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
